---
title: "R/iprobit: Binary and multinomial probit regression using I-priors"
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE)
library(iprobit)
```

[![Build Status](https://travis-ci.org/haziqj/iprobit.svg?branch=master)](https://travis-ci.org/haziqj/iprobit)
[![AppVeyor Build Status](https://ci.appveyor.com/api/projects/status/github/haziqj/iprobit?branch=master&svg=true)](https://ci.appveyor.com/project/haziqj/iprobit)
[![Coverage Status](https://img.shields.io/codecov/c/github/haziqj/iprobit/master.svg)](https://codecov.io/gh/haziqj/iprobit)

This is an `R` package which extends I-prior regression to unordered categorical responses via a probit link function. This allows the user to fit models for classification or inference using fitted probabilities. Estimation is performed using a variational EM algorithm. Visit [http://phd.haziqj.ml](http://phd.haziqj.ml) for details.

## Binary classification (toy example)

#### Model fitting

```{r, cache = TRUE}
dat <- gen_spiral(n = 300)  # generate binary toy example data set
mod <- iprobit(y ~ X1 + X2, dat, one.lam = TRUE, kernel = "FBM")
```

#### Model summary

```{r}
summary(mod)
```

#### Boundary plot for two-dimensional covariates

```{r}
iplot_predict(mod)
```

## Multiclass classification (toy example)

#### Model fit report and parameter estimates

```{r, cache = TRUE}
dat <- gen_mixture(n = 500, m = 4, sd = 1.5)  # generate 4-class toy example data set
(mod <- iprobit(y ~ X1 + X2, dat, control = list(maxit = 10)))
```

#### Boundary plot for two-dimensional covariates

```{r}
iplot_predict(mod)
```

#### Obtain out-of-sample test error rates, predicted classes and probabilities

```{r}
dat.test <- gen_mixture(n = 100, m = 4, sd = 1.5)
(mod.pred <- predict(mod, newdata = dat.test))
```

## Fisher's Iris data set

#### Model fitting (common RKHS scale across classes for each covariate)

```{r, cache = TRUE}
mod <- iprobit(Species ~ ., iris, kernel = "FBM", one.lam = TRUE,
               control = list(alpha0 = 1, lambda0 = 1, 
                              stop.crit = 1e-1,
                              common.RKHS.scale = TRUE, 
                              common.intercept = FALSE))

summary(mod)
```

#### Obtain training error rates, predicted classes and probabilities with posterior quantiles

```{r, cache = TRUE}
fitted(mod, quantiles = TRUE)
```

#### Monitor convergence

```{r}
iplot_lb(mod)
```

#### Plot of training error over time

```{r}
iplot_error(mod)
```

#### Plot of fitted probabilities

```{r}
iplot_fitted(mod)
```

***

Copyright (C) 2017 [Haziq Jamil](http://haziqj.ml).
